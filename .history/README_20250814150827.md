# Facial Emotion Recognition

This project implements a deep learning system for recognizing human facial emotions from images using a Convolutional Neural Network (CNN) in PyTorch. The system is trained on the FER-2013 dataset and can classify images into seven emotions: angry, disgusted, fearful, happy, neutral, sad, and surprised.

## Features

- **Training Pipeline**: Loads, preprocesses, and augments facial images, trains a CNN, and saves the best and final model weights.
- **Validation & Testing**: Splits the training data for validation and evaluates the model on a separate test set.
- **Progress Visualization**: Uses tqdm progress bars for data loading and training/validation steps.
- **GPU Support**: Automatically uses CUDA if available for faster training and inference.
- **Interactive Detection**: Provides a GUI to select any image from your computer and predicts the emotion, displaying all emotion probabilities visually.
- **Modular Code**: Clean separation between training and detection logic.

---

## Project Structure

```
Facial-Emotion-Recognition/
│
├── train.py                # Training and evaluation script (PyTorch)
├── detector.py             # Standalone emotion detector (uses trained model)
├── weights/
│   ├── best_model.pth      # Best model weights (saved during training)
│   └── detector.py         # (empty or backup, not used in main workflow)
├── .history/               # (Auto-backups, not part of main workflow)
└── README.md               # Project documentation
```

---

## Dataset Structure

The code expects the FER-2013 dataset (or similar) organized as:

```
Facial_Emotions/
├── train/
│   ├── angry/
│   ├── disgusted/
│   ├── fearful/
│   ├── happy/
│   ├── neutral/
│   ├── sad/
│   └── surprised/
└── test/
    ├── angry/
    ├── disgusted/
    ├── fearful/
    ├── happy/
    ├── neutral/
    ├── sad/
    └── surprised/
```

Each subfolder contains grayscale face images (48x48 pixels recommended).

---

## How It Works

### 1. Training (`train.py`)

- **Data Loading**: Loads all images from the specified train/test folders, normalizes them, and assigns integer labels.
- **Dataset & DataLoader**: Uses a custom `EmotionDataset` class and PyTorch `DataLoader` for efficient batching.
- **Model Architecture**: Defines a deep CNN (`EmotionCNN`) with three convolutional blocks, batch normalization, dropout, and two fully connected layers.
- **Training Loop**: Trains for a configurable number of epochs, with progress bars and real-time accuracy/loss reporting.
- **Validation**: Splits the training set for validation and tracks the best model using validation accuracy.
- **Testing**: Evaluates the final model on the test set and prints accuracy/loss.
- **Saving**: Saves the best and final model weights in the `weights/` directory.
- **Visualization**: Plots and saves training/validation accuracy and loss curves as `training_history.png`.

### 2. Detection (`detector.py`)

- **Model Loading**: Loads the trained model weights (`best_model.pth`).
- **Image Selection**: Opens a file dialog for the user to select any image from their computer.
- **Preprocessing**: Converts the image to grayscale, resizes to 48x48, normalizes, and prepares it for the model.
- **Prediction**: Runs the image through the model and computes probabilities for all seven emotions.
- **Display**: Shows the image with all emotion probabilities overlaid, sorted from highest to lowest.
- **Loop**: After closing the result window, the file dialog automatically reopens for another image (no need to confirm).

---

## How to Use

### 1. Training

1. Place your dataset in the expected folder structure.
2. Install requirements:
   ```
   pip install torch torchvision opencv-python numpy matplotlib tqdm scikit-learn
   ```
3. Run the training script:
   ```
   python train.py
   ```
   - The script will use GPU if available.
   - Model weights will be saved in `weights/best_model.pth` and `weights/final_model.pth`.
   - Training curves will be saved as `training_history.png`.

### 2. Emotion Detection

1. Ensure `weights/best_model.pth` exists (from training).
2. Run the detector:
   ```
   python detector.py
   ```
3. Select any image file when prompted. The system will display the image with all emotion probabilities.
4. Close the result window to select another image, or click Cancel to exit.

---

## Model Details

- **Input**: Grayscale face image, 48x48 pixels.
- **Output**: Probabilities for each of the 7 emotions.
- **Architecture**: 3 convolutional blocks (Conv2d + BatchNorm + ReLU + MaxPool + Dropout), followed by 2 fully connected layers.
- **Loss**: Cross-entropy.
- **Optimizer**: Adam.
- **Learning Rate Scheduler**: ReduceLROnPlateau.

---

## Customization

- You can adjust `IMG_SIZE`, `BATCH_SIZE`, `EPOCHS`, and other hyperparameters in `train.py`.
- To use a different dataset, ensure it follows the same folder structure and class names.
- The detector can be further extended for batch processing or integrated into other applications.

---

## Requirements

- Python 3.7+
- PyTorch
- OpenCV
- NumPy
- Matplotlib
- tqdm
- scikit-learn
- tkinter (for file dialog, included with standard Python)

---

## Credits

- Model and code: Muhammad-Saad-Akhtar (and contributors)
- Dataset: FER-2013 or compatible facial emotion datasets

---

## License

This project is for educational and research purposes. Please check dataset licensing before commercial use.